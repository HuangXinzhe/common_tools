{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccc4237",
   "metadata": {},
   "source": [
    "# 使用GRU_CRF训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae409a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from gru_crf import LinerCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53a0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Google的colab调用文件时需要添加路径，将文件放入指定的位置才能识别到\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive') \n",
    "# sys.path.append('/content/drive/MyDrive/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35734c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GPU\n",
    "# gpus = tf.config.experimental.list_physical_devices(device_type=\"GPU\")\n",
    "# tf.config.experimental.set_visible_devices(devices=gpus[0], device_type=\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4660fa",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7037ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "X = []\n",
    "feaX = []\n",
    "y = []\n",
    "\n",
    "def data_read(line:str):\n",
    "    lx, lfea, ly = eval(line)\n",
    "    X.append(lx)\n",
    "    feaX.append(lfea)\n",
    "    y.append(ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d91ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.74 s, sys: 131 ms, total: 3.88 s\n",
      "Wall time: 3.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(905, 905)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 读取数据并将提取出数据中的原始文本、文本特征及其对应的标签\n",
    "# readline方法\n",
    "# with open(\"label_old_only_work_project.txt\", encoding='utf-8') as f:\n",
    "#     line = f.readline()\n",
    "#     while line:\n",
    "#         data_read(line)\n",
    "#         line = f.readline()\n",
    "        \n",
    "# readlines方法\n",
    "with open(\"label_old_only_work_project.txt\", encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        data_read(line)\n",
    "\n",
    "# X[0], feaX[0], y[0]\n",
    "len(feaX), len(y)\n",
    "# X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4256f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证数据提取正确： True True True\n",
      "提取后数据数量： 891 891\n"
     ]
    }
   ],
   "source": [
    "# 数据提取\n",
    "X = [[\n",
    "        X[i][j] for j in range(len(y[i])) if y[i][j] != 'O'\n",
    "    ] for i in range(len(y)) if 'project-B' in y[i] or 'project-I' in y[i] or 'work-B' in y[i] or 'work-I' in y[i]\n",
    "]\n",
    "\n",
    "feaX = [[\n",
    "        feaX[i][j] for j in range(len(y[i])) if y[i][j] != 'O'\n",
    "    ] for i in range(len(y)) if 'project-B' in y[i] or 'project-I' in y[i] or 'work-B' in y[i] or 'work-I' in y[i]\n",
    "]\n",
    "\n",
    "y = [[\n",
    "        y[i][j] for j in range(len(y[i])) if y[i][j] != 'O'\n",
    "    ] for i in range(len(y)) if 'project-B' in y[i] or 'project-I' in y[i] or 'work-B' in y[i] or 'work-I' in y[i]\n",
    "]\n",
    "\n",
    "# 验证数据提取正确\n",
    "X_len = np.array([len(i) for i in X])\n",
    "feaX_len = np.array([len(i) for i in feaX])\n",
    "y_len = np.array([len(i) for i in y])\n",
    "print('验证数据提取正确：', max(X_len - feaX_len)==0, max(feaX_len - y_len)==0, max(X_len - y_len)==0)\n",
    "print('提取后数据数量：', len(feaX), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923b3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 3.42 ms, total: 71.4 ms\n",
      "Wall time: 70.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X = [[\n",
    "#        X[i][j] for j in range(len(y[i])) if y[i][j] != 'O'\n",
    "#    ] for i in range(len(y)) if 'project-B' in y[i] or 'work-B' in y[i]\n",
    "#]\n",
    "#\n",
    "#feaX = [[\n",
    "#        feaX[i][j] for j in range(len(y[i])) if y[i][j] != 'O'\n",
    "#    ] for i in range(len(y)) if 'project-B' in y[i] or 'work-B' in y[i]\n",
    "#]\n",
    "#\n",
    "#y = [[\n",
    "#        y[i][j] for j in range(len(y[i])) if y[i][j] != 'O'\n",
    "#    ] for i in range(len(y)) if 'project-B' in y[i] or 'work-B' in y[i] \n",
    "#]\n",
    "\n",
    "X_new = []\n",
    "feaX_new = []\n",
    "y_new = []\n",
    "for i in range(len(y)):\n",
    "    if 'project-B' in y[i] or 'work-B' in y[i]:\n",
    "        X_new.append([X[i][j] for j in range(len(y[i])) if y[i][j] != 'O'])\n",
    "        feaX_new.append([feaX[i][j] for j in range(len(y[i])) if y[i][j] != 'O'])\n",
    "        y_new.append([y[i][j] for j in range(len(y[i])) if y[i][j] != 'O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9791b61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project-B': 0, 'project-I': 1, 'work-B': 2, 'work-I': 3, '<PAD>': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get target encode dictionary\n",
    "tag2id = set()\n",
    "for i in y:\n",
    "    tag2id.update(i)\n",
    "tag2id = list(tag2id)\n",
    "tag2id.sort()\n",
    "tag2id = {k:v for v, k in enumerate(tag2id)}\n",
    "# 添加特征字符标签\n",
    "# tag2id['<start>'] = len(tag2id)\n",
    "tag2id['<PAD>'] = len(tag2id)\n",
    "\n",
    "# label encoding\n",
    "y = [[tag2id[token] for token in sequence] for sequence in y]\n",
    "\n",
    "tag2id #, y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fa8af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project-B': 0, 'project-I': 1, 'work-B': 2, 'work-I': 3, '<PAD>': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建数据标签字典\n",
    "tag2id = set()\n",
    "for i in y_new:\n",
    "    tag2id.update(i)\n",
    "tag2id = list(tag2id)\n",
    "tag2id.sort()\n",
    "tag2id = {k:v for v, k in enumerate(tag2id)}\n",
    "# 添加特征字符标签\n",
    "# tag2id['<start>'] = len(tag2id)\n",
    "tag2id['<PAD>'] = len(tag2id)\n",
    "\n",
    "# label encoding\n",
    "y_new = [[tag2id[token] for token in sequence] for sequence in y_new]\n",
    "\n",
    "tag2id #, y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735b327b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 612, 24), (891, 612))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seqence padding\n",
    "max_len = max([len(i) for i in y])\n",
    "fea_dim = len(feaX[0][0])\n",
    "\n",
    "feaX = np.array(\n",
    "    [i + [[0] * fea_dim] * (max_len - len(i)) for i in feaX]\n",
    ")\n",
    "y = np.array(\n",
    "    [i + [tag2id['<PAD>']] * (max_len - len(i)) for i in y]\n",
    ")\n",
    "\n",
    "feaX.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618998bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 612, 24), (891, 612))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seqence padding\n",
    "max_len = max([len(i) for i in y_new])\n",
    "fea_dim = len(feaX_new[0][0])\n",
    "\n",
    "feaX_new = np.array(\n",
    "    [i + [[0] * fea_dim] * (max_len - len(i)) for i in feaX_new]\n",
    ")\n",
    "y_new = np.array(\n",
    "    [i + [tag2id['<PAD>']] * (max_len - len(i)) for i in y_new]\n",
    ")\n",
    "\n",
    "feaX_new.shape, y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fb5d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 612, 24), (712, 612), (179, 612, 24), (179, 612))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据划分\n",
    "feaX_train, feaX_valid, y_train, y_valid = train_test_split(\n",
    "    feaX, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "feaX_train.shape, y_train.shape, feaX_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119efc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 612, 24), (712, 612), (179, 612, 24), (179, 612))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据划分\n",
    "feaX_train, feaX_valid, y_train, y_valid = train_test_split(feaX_new, \n",
    "                                                            y_new, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=39)\n",
    "\n",
    "feaX_train.shape, y_train.shape, feaX_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f9e45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:24:33.127322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18,\n",
       " [<tf.Tensor: shape=(40, 612, 24), dtype=float64, numpy=\n",
       "  array([[[0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.17241379, 0.07692308],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.17931034, 0.15384615],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.1862069 , 0.23076923],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.12621359, 0.09090909],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.13106796, 0.18181818],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.13592233, 0.27272727],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.14864865, 0.33333333],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.16216216, 0.66666667],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.17567568, 1.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.22222222, 0.06666667],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.23015873, 0.13333333],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.23809524, 0.2       ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.13166144, 0.11111111],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.13479624, 0.22222222],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.13793103, 0.33333333],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.29577465, 0.2       ],\n",
       "          [0.        , 0.        , 1.        , ..., 1.        ,\n",
       "           0.30985915, 0.4       ],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.32394366, 0.6       ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]]])>,\n",
       "  <tf.Tensor: shape=(40, 612), dtype=int64, numpy=\n",
       "  array([[2, 3, 3, ..., 4, 4, 4],\n",
       "         [2, 3, 3, ..., 4, 4, 4],\n",
       "         [2, 3, 3, ..., 4, 4, 4],\n",
       "         ...,\n",
       "         [2, 3, 3, ..., 4, 4, 4],\n",
       "         [2, 3, 3, ..., 4, 4, 4],\n",
       "         [2, 3, 3, ..., 4, 4, 4]])>,\n",
       "  <tf.Tensor: shape=(40, 612), dtype=float64, numpy=\n",
       "  array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.]])>],\n",
       " [<tf.Tensor: shape=(32, 612, 24), dtype=float64, numpy=\n",
       "  array([[[0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.24096386, 0.08333333],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.25301205, 0.16666667],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.26506024, 0.25      ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.43902439, 0.125     ],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.46341463, 0.25      ],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.48780488, 0.375     ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.25806452, 0.08333333],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.29032258, 0.16666667],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.32258065, 0.25      ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.08357349, 0.2       ],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.08645533, 0.4       ],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.08933718, 0.6       ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.27142857, 0.07142857],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.28571429, 0.14285714],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.3       , 0.21428571],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.25263158, 0.33333333],\n",
       "          [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "           0.26315789, 0.66666667],\n",
       "          [0.        , 0.        , 0.        , ..., 2.        ,\n",
       "           0.27368421, 1.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]]])>,\n",
       "  <tf.Tensor: shape=(32, 612), dtype=int64, numpy=\n",
       "  array([[2, 3, 3, ..., 4, 4, 4],\n",
       "         [0, 1, 1, ..., 4, 4, 4],\n",
       "         [2, 3, 3, ..., 4, 4, 4],\n",
       "         ...,\n",
       "         [2, 3, 3, ..., 4, 4, 4],\n",
       "         [2, 3, 3, ..., 4, 4, 4],\n",
       "         [2, 3, 3, ..., 4, 4, 4]])>,\n",
       "  <tf.Tensor: shape=(32, 612), dtype=float64, numpy=\n",
       "  array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 0., 0.]])>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集生成\n",
    "def data_generater(X, y, batch_size, tag2id, is_mask=True):\n",
    "    sample_num = X.shape[0]\n",
    "    data = []\n",
    "    if is_mask:\n",
    "        for i in range(int(sample_num/batch_size) + 1):\n",
    "            if i * batch_size < sample_num:\n",
    "                data.append([\n",
    "                    tf.constant(X[i * batch_size : (i + 1) * batch_size])\n",
    "                    , tf.constant(y[i * batch_size : (i + 1) * batch_size])\n",
    "                    , tf.constant(np.where(y[i * batch_size : (i + 1) * batch_size] == tag2id['<PAD>'], 0., 1.))\n",
    "                ])\n",
    "    else:\n",
    "        for i in range(int(sample_num/batch_size) + 1):\n",
    "            if i * batch_size < sample_num:\n",
    "                data.append([\n",
    "                    tf.constant(X[i * batch_size : (i + 1) * batch_size])\n",
    "                    , tf.constant(y[i * batch_size : (i + 1) * batch_size])\n",
    "                ])\n",
    "    return data\n",
    "\n",
    "\n",
    "batch_size = 40\n",
    "train_data = data_generater(feaX_train, y_train, batch_size, tag2id)\n",
    "valid_data = [\n",
    "    feaX_valid\n",
    "    , y_valid\n",
    "    , tf.constant(np.where(y_valid == tag2id['<PAD>'], 0., 1.))\n",
    "]\n",
    "\n",
    "len(train_data), train_data[0], train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "125df21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step:   0%|                                              | 0/18 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[24479] = 97920 is not in [0, 97920) [Op:GatherV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gg/_6rvqtbj61v2wg9llh2bnvp80000gn/T/ipykernel_23826/1128565999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinerCRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag2id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# model.load_weights('./checkpoints/best_model')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/common_tools/nlp/model/gru_crf_model/gru_crf.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, valid_data, epochs, gard_theta, patience, min_delta, checkpoint_dir, init_best_accuracy, verbose)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# 参数更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mtrain_varb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/common_tools/nlp/model/gru_crf_model/gru_crf.py\u001b[0m in \u001b[0;36mCRF_loss\u001b[0;34m(self, emission, y_true, real_len, transition)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mCRF_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         loss, _ = tfa.text.crf_log_likelihood(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0memission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36mcrf_log_likelihood\u001b[0;34m(inputs, tag_indices, sequence_lengths, transition_params)\u001b[0m\n\u001b[1;32m    239\u001b[0m         )\n\u001b[1;32m    240\u001b[0m     \u001b[0mtransition_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     sequence_scores = crf_sequence_score(\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36mcrf_sequence_score\u001b[0;34m(inputs, tag_indices, sequence_lengths, transition_params)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msequence_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_single_seq_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_multi_seq_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36m_multi_seq_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_multi_seq_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Compute the scores of the given tag sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0munary_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_unary_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         binary_scores = crf_binary_score(\n\u001b[1;32m     99\u001b[0m             \u001b[0mtag_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36mcrf_unary_score\u001b[0;34m(tag_indices, sequence_lengths, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     unary_scores = tf.reshape(\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_tag_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[24479] = 97920 is not in [0, 97920) [Op:GatherV2]"
     ]
    }
   ],
   "source": [
    "from gru_crf import *\n",
    "model = LinerCRF(len(tag2id) - 1)\n",
    "# model.load_weights('./checkpoints/best_model')\n",
    "model.train(train_data, valid_data, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1275f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
